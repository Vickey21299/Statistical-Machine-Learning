{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12665, 784)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "(4923, 784)\n",
      "(2000, 784)\n",
      "(10665, 784)\n",
      "(2000,)\n",
      "(784, 5)\n",
      "Shape of reduced training data: (10665, 5)\n",
      "Shape of reduced validation data: (2000, 5)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mnist_data = np.load('mnist.npz')\n",
    "\n",
    "# Loading data \n",
    "X_train = mnist_data['x_train']\n",
    "Y_train = mnist_data['y_train']\n",
    "X_test = mnist_data['x_test']\n",
    "Y_test = mnist_data['y_test']\n",
    "\n",
    "# Filtering data for classes 0 and 1\n",
    "is_class_01 = (Y_train == 0) | (Y_train == 1)\n",
    "X_train = X_train[is_class_01]\n",
    "Y_train = Y_train[is_class_01]\n",
    "\n",
    "is_class_02 = (Y_test == 0) | (Y_test == 1)\n",
    "X_test = X_test[is_class_02]\n",
    "Y_test = Y_test[is_class_02]\n",
    "\n",
    "# Normalize \n",
    "X_train = X_train.reshape(-1, 28 * 28) / 255.0\n",
    "X_test = X_test.reshape(-1, 28 * 28) / 255.0\n",
    "print(X_train.shape)\n",
    "\n",
    "# Relabelling\n",
    "Y_train = np.where(Y_train==0,-1,1)\n",
    "Y_test = np.where(Y_test == 0,-1,1)\n",
    "\n",
    "# Spliting the dataset\n",
    "num_samples_class_0 = 1000\n",
    "num_samples_class_1 = 1000\n",
    "\n",
    "X_train_class_0 = X_train[Y_train == -1]\n",
    "Y_train_class_0 = Y_train[Y_train == -1]\n",
    "\n",
    "X_train_class_1 = X_train[Y_train == 1]\n",
    "Y_train_class_1 = Y_train[Y_train == 1]\n",
    "\n",
    "# X_test_class_2 = X_test[Y_test == -1]\n",
    "# Y_test_class_2 = Y_test[Y_test == -1]\n",
    "\n",
    "# X_test_class_3 = X_test[Y_test == 1]\n",
    "# Y_test_class_3 = Y_test[Y_test == 1]\n",
    "\n",
    "print(X_train_class_0)\n",
    "# Validation set\n",
    "X_train_val = np.vstack((X_train_class_0[:num_samples_class_0], X_train_class_1[:num_samples_class_1]))\n",
    "Y_train_val = np.hstack((Y_train_class_0[:num_samples_class_0], Y_train_class_1[:num_samples_class_1]))\n",
    "\n",
    "# Training set\n",
    "X_train = np.vstack((X_train_class_0[num_samples_class_0:], X_train_class_1[num_samples_class_1:]))\n",
    "Y_train = np.hstack((Y_train_class_0[num_samples_class_0:], Y_train_class_1[num_samples_class_1:]))\n",
    "\n",
    "print(X_train_class_0[num_samples_class_0:].shape)\n",
    "print(X_train_val.shape)\n",
    "print(X_train.shape)\n",
    "print(Y_train_val.shape)\n",
    "\n",
    "#Mean of x_train and X_test\n",
    "mean_vector = np.mean(X_train, axis=0)\n",
    "mean_vector1 = np.mean(X_test, axis=0)\n",
    "\n",
    "cov_matrix = np.cov((X_train - mean_vector).T)\n",
    "cov_matrix1 = np.cov((X_test - mean_vector1).T)\n",
    "\n",
    "eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
    "eigenvalues1, eigenvectors1 = np.linalg.eigh(cov_matrix1)\n",
    "\n",
    "# Sort eigenvectors \n",
    "sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "top_p_indices = sorted_indices[:5]\n",
    "sorted_indices1 = np.argsort(eigenvalues1)[::-1]\n",
    "top_p_indices1 = sorted_indices1[:5]\n",
    "\n",
    "pca_matrix = eigenvectors[:, top_p_indices]\n",
    "pca_matrix1 = eigenvectors1[:, top_p_indices1]\n",
    "\n",
    "print(pca_matrix.shape)\n",
    "X_train_pca = np.dot(X_train - mean_vector, pca_matrix)\n",
    "X_val_pca = np.dot(X_train_val - mean_vector, pca_matrix)\n",
    "X_test_pca = np.dot(X_test - mean_vector1, pca_matrix)\n",
    "\n",
    "print(\"Shape of reduced training data:\", X_train_pca.shape)\n",
    "print(\"Shape of reduced validation data:\", X_val_pca.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data after PCA:\n",
      "Dimension 1: [-9.14050887 -9.12628801 -8.98098105 ...  4.42735384  4.46459577\n",
      "  4.4702065 ]\n",
      "Dimension 2: [-6.06722951 -5.9901054  -5.54732112 ...  3.79543166  3.85617239\n",
      "  3.90544954]\n",
      "Dimension 3: [-5.56645578 -5.49364676 -5.47483353 ...  4.95061807  5.00174571\n",
      "  5.00814084]\n",
      "Dimension 4: [-5.31601761 -5.31149254 -5.22410596 ...  4.88780727  4.9698394\n",
      "  5.09538818]\n",
      "Dimension 5: [-3.6491333  -3.59755316 -3.57806115 ...  4.64196635  4.65935191\n",
      "  5.42137539]\n",
      "\n",
      "validation data after PCA:\n",
      "Dimension 1: [-8.96990919 -8.59099587 -8.47369653 ...  4.32894399  4.3445438\n",
      "  4.3650654 ]\n",
      "Dimension 2: [-5.18271121 -4.98273991 -4.97617406 ...  3.61741336  3.78122422\n",
      "  3.84658567]\n",
      "Dimension 3: [-5.72106446 -5.32494584 -5.29495264 ...  4.82954624  4.8421774\n",
      "  4.93588225]\n",
      "Dimension 4: [-5.33371114 -5.32356401 -5.19678641 ...  4.21573374  4.25409641\n",
      "  4.28758238]\n",
      "Dimension 5: [-3.53086225 -3.48735364 -3.44431312 ...  3.64003466  3.83711548\n",
      "  4.03330041]\n"
     ]
    }
   ],
   "source": [
    "# Finding unique values for each dimension and Sorting unique values in ascending order \n",
    "unique_values_train = [np.unique(X_train_pca[:, i]) for i in range(X_train_pca.shape[1])]\n",
    "sorted_unique_values_train = [np.sort(vals) for vals in unique_values_train]\n",
    "\n",
    "unique_values_val = [np.unique(X_val_pca[:, i]) for i in range(X_val_pca.shape[1])]\n",
    "sorted_unique_values_val = [np.sort(vals) for vals in unique_values_val]\n",
    "\n",
    "print(\"training data after PCA:\")\n",
    "for i, vals in enumerate(sorted_unique_values_train):\n",
    "    print(f\"Dimension {i+1}: {vals}\")\n",
    "print(\"\\nvalidation data after PCA:\")\n",
    "for i, vals in enumerate(sorted_unique_values_val):\n",
    "    print(f\"Dimension {i+1}: {vals}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 2.679000173739841\n",
      "Best dim: 1\n",
      "Best midpoint: 0.7445328110204548\n"
     ]
    }
   ],
   "source": [
    "# Weight calculation and best stump parameters\n",
    "weights = np.ones(len(Y_train)) / len(Y_train)\n",
    "best_dim = None\n",
    "min_error = float('inf')\n",
    "\n",
    "best_midpoint = None\n",
    "# For avoiding division by zero\n",
    "epsilon = 1e-10\n",
    "\n",
    "best_direction = None\n",
    "\n",
    "# Midpoint calculation\n",
    "for dimension in range(X_train_pca.shape[1]):\n",
    "    unique_vals = sorted_unique_values_train[dimension]\n",
    "    \n",
    "    midpoints = (unique_vals[:-1] + unique_vals[1:]) / 2\n",
    "    \n",
    "    for midpoint in midpoints:\n",
    "        predictions = np.where(X_train_pca[:, dimension] <= midpoint, -1, 1)\n",
    "        error = np.sum(weights[Y_train != predictions])\n",
    "        \n",
    "        #update best parameters\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "\n",
    "            best_dim = dimension\n",
    "            best_midpoint = midpoint\n",
    "            best_direction = predictions.copy()\n",
    "\n",
    "  \n",
    "alpha = 0.5 * np.log((1 - min_error+ epsilon) / (min_error+epsilon))\n",
    "\n",
    "# Update weights\n",
    "weights *= np.exp(-alpha * Y_train * best_direction)\n",
    "weights /= np.sum(weights)\n",
    "\n",
    "# H1(x)\n",
    "h1_x = best_direction\n",
    "\n",
    "print(\"Alpha:\", alpha)\n",
    "\n",
    "print(\"Best dim:\", best_dim + 1)\n",
    "print(\"Best midpoint:\", best_midpoint)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.5870650045280318\n",
      "Iteration 1: Validation Accuracy = 0.974\n",
      "alpha 0.7206308952002222\n",
      "Iteration 2: Validation Accuracy = 0.9725\n",
      "alpha 0.6933211182847129\n",
      "Iteration 3: Validation Accuracy = 0.5015\n",
      "alpha 0.4672848060536943\n",
      "Iteration 4: Validation Accuracy = 0.6875\n",
      "alpha 0.47285593002262205\n",
      "Iteration 5: Validation Accuracy = 0.9725\n",
      "alpha 0.43952341640152087\n",
      "Iteration 6: Validation Accuracy = 0.974\n",
      "alpha 0.4019655511148384\n",
      "Iteration 7: Validation Accuracy = 0.408\n",
      "alpha 0.23743042793367233\n",
      "Iteration 8: Validation Accuracy = 0.983\n",
      "alpha 0.3618974560353523\n",
      "Iteration 9: Validation Accuracy = 0.984\n",
      "alpha 0.2576931419846353\n",
      "Iteration 10: Validation Accuracy = 0.9725\n",
      "alpha 0.31616488358467215\n",
      "Iteration 11: Validation Accuracy = 0.4605\n",
      "alpha 0.2669646503727792\n",
      "Iteration 12: Validation Accuracy = 0.678\n",
      "alpha 0.2508965149374222\n",
      "Iteration 13: Validation Accuracy = 0.9725\n",
      "alpha 0.2653905003493111\n",
      "Iteration 14: Validation Accuracy = 0.6005\n",
      "alpha 0.2056844187882642\n",
      "Iteration 15: Validation Accuracy = 0.9725\n",
      "alpha 0.20880940845266646\n",
      "Iteration 16: Validation Accuracy = 0.984\n",
      "alpha 0.21801616064570445\n",
      "Iteration 17: Validation Accuracy = 0.382\n",
      "alpha 0.16159751144060133\n",
      "Iteration 18: Validation Accuracy = 0.974\n",
      "alpha 0.18204901242228533\n",
      "Iteration 19: Validation Accuracy = 0.9725\n",
      "alpha 0.1537895345239435\n",
      "Iteration 20: Validation Accuracy = 0.974\n",
      "alpha 0.13316930066184282\n",
      "Iteration 21: Validation Accuracy = 0.9725\n",
      "alpha 0.14087406076730266\n",
      "Iteration 22: Validation Accuracy = 0.6895\n",
      "alpha 0.11316678407777384\n",
      "Iteration 23: Validation Accuracy = 0.6005\n",
      "alpha 0.14753250371217752\n",
      "Iteration 24: Validation Accuracy = 0.388\n",
      "alpha 0.11203237108269373\n",
      "Iteration 25: Validation Accuracy = 0.984\n",
      "alpha 0.15850337424974434\n",
      "Iteration 26: Validation Accuracy = 0.983\n",
      "alpha 0.10934969211037278\n",
      "Iteration 27: Validation Accuracy = 0.606\n",
      "alpha 0.11456277970819376\n",
      "Iteration 28: Validation Accuracy = 0.562\n",
      "alpha 0.11209212272213338\n",
      "Iteration 29: Validation Accuracy = 0.974\n",
      "alpha 0.10896962487481245\n",
      "Iteration 30: Validation Accuracy = 0.408\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 50\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIteration \u001b[39m\u001b[38;5;132;01m{\u001b[39;00miteration\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: Validation Accuracy = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy_val\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Ploting accuracy on validation set vs. number of trees\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m     51\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m31\u001b[39m), accuracies_val, marker\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mo\u001b[39m\u001b[38;5;124m'\u001b[39m, linestyle\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     52\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy on Validation Set vs. Number of Trees\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "predictions_train = []\n",
    "accuracies_val = []\n",
    "\n",
    "for iteration in range(30):\n",
    "    best_dim = None\n",
    "    best_direction = None\n",
    "    min_error = float('inf')\n",
    "    # for avoiding division by zero\n",
    "    epsilon = 1e-10  \n",
    "\n",
    "    best_midpoint = None\n",
    "    for dim in range(X_train_pca.shape[1]):\n",
    "        unique_vals = sorted_unique_values_train[dim]\n",
    "\n",
    "        midpoints = (unique_vals[:-1] + unique_vals[1:]) / 2\n",
    "\n",
    "        # Midpoint calculation\n",
    "        for midpoint in midpoints:\n",
    "            predictions = np.where(X_train_pca[:, dim] <= midpoint, -1, 1)\n",
    "            error = np.sum(weights[Y_train != predictions])\n",
    "\n",
    "            if error < min_error:\n",
    "                best_dim = dim\n",
    "                min_error = error\n",
    "                best_midpoint = midpoint\n",
    "                best_direction = predictions.copy()\n",
    "\n",
    "    alpha = 0.5 * np.log((1 - min_error+ epsilon) / (min_error+ epsilon))\n",
    "\n",
    "\n",
    "    print(\"alpha\",alpha)\n",
    "\n",
    "\n",
    "    # Update weights \n",
    "    weights *= np.exp(-alpha * Y_train * best_direction)\n",
    "    weights /= np.sum(weights)\n",
    "\n",
    "    # H(x)\n",
    "    h_x = best_direction\n",
    "    predictions_train.append(h_x)\n",
    "\n",
    "    # accuracy on validation set\n",
    "    val_predictions = np.where(X_val_pca[:, best_dim] <= best_midpoint, -1, 1)\n",
    "    accuracy_val = np.mean(Y_train_val == val_predictions)\n",
    "    accuracies_val.append(accuracy_val)\n",
    "\n",
    "    print(f\"Iteration {iteration + 1}: Validation Accuracy = {accuracy_val}\")\n",
    "\n",
    "# Ploting accuracy on validation set vs. number of trees\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(range(1, 31), accuracies_val, marker='o', linestyle='-')\n",
    "plt.title('Accuracy on Validation Set vs. Number of Trees')\n",
    "plt.xlabel('Number of Trees')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.grid(True)\n",
    "plt.ylim(-5, 1.0)\n",
    "plt.show()\n",
    "\n",
    "# index of the best accuracy\n",
    "best_accuracy_index = np.argmax(accuracies_val)\n",
    "\n",
    "# Evaluate the best tree on the test set\n",
    "best_predictions_train = predictions_train[best_accuracy_index]\n",
    "\n",
    "best_val_predictions = np.where(X_val_pca[:, best_dim] <= best_midpoint, -1, 1)\n",
    "\n",
    "best_test_predictions = np.where(X_test_pca[:, best_dim] <= best_midpoint, -1, 1)\n",
    "\n",
    "accuracy_test = np.mean(Y_test== best_test_predictions)\n",
    "\n",
    "print(f\"Best Test Acc = {accuracy_test}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
