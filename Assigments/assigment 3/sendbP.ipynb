{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from node import Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Matrix shape for X_train: (784, 10)\n",
      "Reduced X_train shape: (18623, 10)\n",
      "PCA Matrix shape for x_test: (784, 10)\n",
      "Reduced x_test shape: (3147, 10)\n"
     ]
    }
   ],
   "source": [
    "mnist_data = np.load('mnist.npz')\n",
    "X_train = mnist_data['x_train']\n",
    "y_train = mnist_data['y_train']\n",
    "x_test = mnist_data['x_test']\n",
    "y_test = mnist_data['y_test']\n",
    "\n",
    "mask = (y_train <3)\n",
    "X_train = X_train[mask]\n",
    "y_train = y_train[mask]\n",
    "\n",
    "mask2=(y_test <3)\n",
    "x_test = x_test[mask2]\n",
    "y_test = y_test[mask2]\n",
    "import numpy as np\n",
    "\n",
    "def pca_transform(data, n_components=10):\n",
    "    # Reshape the data if necessary\n",
    "    data = data.reshape(data.shape[0], -1)\n",
    "    \n",
    "    # Calculate mean\n",
    "    mean = np.mean(data, axis=0)\n",
    "    \n",
    "    # Center the data\n",
    "    data_centered = data - mean\n",
    "    \n",
    "    # Calculate covariance matrix\n",
    "    cov_matrix = np.cov(data_centered, rowvar=False)\n",
    "    \n",
    "    # Compute eigenvectors and eigenvalues\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    \n",
    "    # Sort eigenvalues and corresponding eigenvectors\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvectors_sorted = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "    # Select top n_components eigenvectors\n",
    "    pca_matrix = eigenvectors_sorted[:, :n_components]\n",
    "    \n",
    "    # Project data onto the principal components\n",
    "    data_reduced = np.dot(data_centered, pca_matrix)\n",
    "    \n",
    "    return data_reduced, pca_matrix\n",
    "\n",
    "# Example usage:\n",
    "# Assuming X_train and x_test are your datasets\n",
    "X_reduced, pca_matrix = pca_transform(X_train, n_components=10)\n",
    "print(\"PCA Matrix shape for X_train:\", pca_matrix.shape)\n",
    "print(\"Reduced X_train shape:\", X_reduced.shape)\n",
    "\n",
    "X_reduced1, pca_matrix1 = pca_transform(x_test, n_components=10)\n",
    "print(\"PCA Matrix shape for x_test:\", pca_matrix1.shape)\n",
    "print(\"Reduced x_test shape:\", X_reduced1.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def pca(data, n_components=10):\n",
    "#     data_mean = np.mean(data, axis=0)\n",
    "#     data_centered = data - data_mean\n",
    "#     covariance_matrix = np.cov(data_centered, rowvar=False)\n",
    "#     eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    \n",
    "#     # Step 5: Sort eigenvectors and eigenvalues in descending order\n",
    "#     sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "#     sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "#     sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "#     # Step 6: Choose top n_components eigenvectors\n",
    "#     U = sorted_eigenvectors[:, :n_components]\n",
    "    \n",
    "#     # Step 7: Project the data onto the top n_components eigenvectors\n",
    "#     Y = np.dot(U.T, data_centered.T)\n",
    "#     # Step 9: Further reduce dimensionality if needed\n",
    "#     Up = U[:, :n_components]\n",
    "#     data_reduced = np.dot( data_centered , Up)\n",
    "    \n",
    "#     return data_reduced\n",
    "# pca_matrix = pca(X_train, n_components=10)\n",
    "# print(pca_matrix.shape)\n",
    "# pca_matrix_test= pca(x_test, n_components=10)\n",
    "# print(pca_matrix_test.shape)\n",
    "# # plotting the graph\n",
    "# plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y_train, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeClassifier():\n",
    "    def __init__(self, min_samples_split=2, max_depth=2):\n",
    "        self.root = None\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        \n",
    "    def build_tree(self, dataset, curr_depth=0):\n",
    "        X, Y = dataset[:,:-1], dataset[:,-1]\n",
    "        num_samples, num_features = np.shape(X)\n",
    "\n",
    "        if num_samples>=self.min_samples_split and curr_depth<=self.max_depth:\n",
    "            best_split = self.get_best_split(dataset, num_samples, num_features)\n",
    "            if best_split[\"info_gain\"]>0:\n",
    "                left_subtree = self.build_tree(best_split[\"dataset_left\"], curr_depth+1)\n",
    "                right_subtree = self.build_tree(best_split[\"dataset_right\"], curr_depth+1)\n",
    "                return Node(best_split[\"feature_index\"], best_split[\"threshold\"], \n",
    "                            left_subtree, right_subtree, best_split[\"info_gain\"])\n",
    "        leaf_value = self.calculate_leaf_value(Y)\n",
    "        return Node(value=leaf_value)\n",
    "    \n",
    "    def get_best_split(self, dataset, num_samples, num_features):\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "        for feature_index in range(num_features):\n",
    "            feature_values = dataset[:, feature_index]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "            for threshold in possible_thresholds:\n",
    "                dataset_left, dataset_right = self.split(dataset, feature_index, threshold)\n",
    "                if len(dataset_left)>0 and len(dataset_right)>0:\n",
    "                    y, left_y, right_y = dataset[:, -1], dataset_left[:, -1], dataset_right[:, -1]\n",
    "                    curr_info_gain = self.information_gain(y, left_y, right_y, \"gini\")\n",
    "                    if curr_info_gain>max_info_gain:\n",
    "                        best_split[\"feature_index\"] = feature_index\n",
    "                        best_split[\"threshold\"] = threshold\n",
    "                        best_split[\"dataset_left\"] = dataset_left\n",
    "                        best_split[\"dataset_right\"] = dataset_right\n",
    "                        best_split[\"info_gain\"] = curr_info_gain\n",
    "                        max_info_gain = curr_info_gain\n",
    "    \n",
    "        return best_split\n",
    "    \n",
    "    def split(self, dataset, feature_index, threshold):\n",
    "        dataset_left = np.array([row for row in dataset if row[feature_index]<=threshold])\n",
    "        dataset_right = np.array([row for row in dataset if row[feature_index]>threshold])\n",
    "        return dataset_left, dataset_right\n",
    "    \n",
    "    def information_gain(self, parent, l_child, r_child, mode=\"entropy\"):\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "        if mode==\"gini\":\n",
    "            gain = self.gini_index(parent) - (weight_l*self.gini_index(l_child) + weight_r*self.gini_index(r_child))\n",
    "        else:\n",
    "            gain = self.entropy(parent) - (weight_l*self.entropy(l_child) + weight_r*self.entropy(r_child))\n",
    "        return gain\n",
    "    \n",
    "    def gini_index(self, y): \n",
    "        class_labels = np.unique(y)\n",
    "        gini = 0\n",
    "        for cls in class_labels:\n",
    "            p_cls = len(y[y == cls]) / len(y)\n",
    "            gini += p_cls**2\n",
    "        return 1 - gini\n",
    "        \n",
    "    def calculate_leaf_value(self, Y):   \n",
    "        Y = list(Y)\n",
    "        return max(Y, key=Y.count)\n",
    "    def fit(self, X, Y):  \n",
    "        dataset = np.concatenate((X, Y), axis=1)\n",
    "        self.root = self.build_tree(dataset)\n",
    "    \n",
    "    def predict(self, X):  \n",
    "        preditions = [self.make_prediction(x, self.root) for x in X]\n",
    "        return preditions\n",
    "    \n",
    "    def make_prediction(self, x, tree):\n",
    "        if tree.value!=None: return tree.value\n",
    "        feature_val = x[tree.feature_index]\n",
    "        if feature_val<=tree.threshold:\n",
    "            return self.make_prediction(x, tree.left)\n",
    "        else:\n",
    "            return self.make_prediction(x, tree.right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.961\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 0; dimension is 1000 but corresponding boolean dimension is 3147",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39munique(y_test):\n\u001b[0;32m     26\u001b[0m     class_mask \u001b[38;5;241m=\u001b[39m (y_test \u001b[38;5;241m==\u001b[39m c)\n\u001b[1;32m---> 27\u001b[0m     class_accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test[class_mask], \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[43m(\u001b[49m\u001b[43mY_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mclass_mask\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     28\u001b[0m     class_accuracies[c] \u001b[38;5;241m=\u001b[39m class_accuracy\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClass-wise accuracies:\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_accuracies)\n",
      "\u001b[1;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 0; dimension is 1000 but corresponding boolean dimension is 3147"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reshape y_train to match classifier's requirements\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "i=1000\n",
    "\n",
    "# Instantiate the DecisionTreeClassifier with desired parameters\n",
    "classifier = DecisionTreeClassifier(min_samples_split=3, max_depth=2)\n",
    "\n",
    "# Fit the classifier on the reduced training data\n",
    "classifier.fit(X_reduced[:i], y_train[:i])\n",
    "\n",
    "# Predict the labels for the test data\n",
    "Y_pred = classifier.predict(np.real(X_reduced1))\n",
    "\n",
    "# Calculate the overall accuracy\n",
    "overall_accuracy = accuracy_score(y_test, np.real(Y_pred))\n",
    "\n",
    "print(\"Overall Accuracy:\", overall_accuracy)\n",
    "\n",
    "# Calculate class-wise accuracies\n",
    "class_accuracies = {}\n",
    "for c in np.unique(y_test):\n",
    "    class_mask = (y_test == c)\n",
    "    class_accuracy = accuracy_score(y_test[class_mask], np.real(Y_pred)[class_mask])\n",
    "    class_accuracies[c] = class_accuracy\n",
    "\n",
    "print(\"Class-wise accuracies:\", class_accuracies)\n",
    "\n",
    "# Convert class-wise accuracies to DataFrame and sort\n",
    "class_accuracies_df = pd.DataFrame(class_accuracies.items(), columns=['Class', 'Accuracy'])\n",
    "class_accuracies_df = class_accuracies_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(class_accuracies_df)\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(len(class_accuracies_df)), class_accuracies_df['Accuracy'], align='center')\n",
    "ax.set_xticks(range(len(class_accuracies_df)))\n",
    "ax.set_xticklabels(class_accuracies_df['Class'])\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_title('Class-wise Accuracy')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Accuracy: 0.6742929774388307\n",
      "Class 0 Accuracy: 0.45918367346938777\n",
      "Class 1 Accuracy: 0.9392070484581497\n",
      "Class 2 Accuracy: 0.5872093023255814\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv/0lEQVR4nO3de1iUdf7/8deAAoqAGghirIhrecwDKBlqly1lZaZlnuonxqptBR6i3LRUtIOo5SHPm5vat1BYLa1W0ww1Nc0TeUrT1AwPgZIJhAks3L8/upxdAo1BdPDj83Fdc13ymfueeQ/S5bN77puxWZZlCQAAwBAuzh4AAACgIhE3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQN8ANKDg4WE8++aSzx6gQx48fl81m06JFi5w9CgBDEDdAJXL06FH97W9/U0hIiDw8POTt7a2IiAi99dZb+vXXX509npFWrVolm82mwMBAFRUVOXscABWgirMHAPCblStXqlevXnJ3d1dUVJSaN2+u/Px8bd68WSNGjNA333yjt99+29ljVrj69evr119/VdWqVZ3y/ImJiQoODtbx48e1bt06RUZGOmUOABWHuAEqge+//159+/ZV/fr1tW7dOtWtW9d+X0xMjI4cOaKVK1c6ccJrx2azycPDwynPnZubq48++kgJCQlauHChEhMTK23c5ObmytPT09ljADcE3pYCKoHJkyfrl19+0TvvvFMsbC7585//rGHDhl12/3PnzumFF15QixYtVKNGDXl7e+uBBx7Qnj17Smw7c+ZMNWvWTNWrV1etWrUUFhamxYsX2+/PycnR8OHDFRwcLHd3d9WpU0f33nuvUlNTr/ga4uLidMstt8iyLPvakCFDZLPZNGPGDPtaRkaGbDab5s6dK6n0c27S09MVHR2tW2+9Ve7u7qpbt666d++u48ePF3vOTz/9VB07dpSnp6e8vLzUtWtXffPNN1ec838tX75cv/76q3r16qW+ffvqww8/1MWLF0tsd/HiRY0bN0633XabPDw8VLduXT366KM6evSofZuioiK99dZbatGihTw8POTn56f7779fO3fuvOzrvMRms2ncuHH2r8eNGyebzaYDBw7o8ccfV61atdShQwdJ0t69e/Xkk0/a37oMCAjQX//6V/30008lHvfUqVMaOHCgAgMD5e7urgYNGuiZZ55Rfn6+jh07JpvNpmnTppXYb8uWLbLZbFqyZEmZv5dAZULcAJXAJ598opCQEN11113l2v/YsWNasWKFHnroIU2dOlUjRozQvn37dPfdd+v06dP27ebPn6+hQ4eqadOmmj59usaPH69WrVpp27Zt9m2efvppzZ07Vz179tScOXP0wgsvqFq1ajp48OAVZ+jYsaPOnTtXLC42bdokFxcXbdq0qdiaJHXq1Omyj9WzZ08tX75c0dHRmjNnjoYOHaqcnBylpaXZt3nvvffUtWtX1ahRQ5MmTdKYMWN04MABdejQoUQEXU5iYqI6d+6sgIAA9e3bVzk5Ofrkk0+KbVNYWKiHHnpI48ePV2hoqKZMmaJhw4YpKytL+/fvt283cOBADR8+XEFBQZo0aZJGjhwpDw8PffXVV2WapTS9evXShQsXNGHCBA0ePFiStHbtWh07dkzR0dGaOXOm+vbtq6SkJD344IPFwvL06dNq166dkpKS1KdPH82YMUP9+/fXF198oQsXLigkJEQRERFKTEws9fvi5eWl7t27l3t2wKksAE6VlZVlSbK6d+9e5n3q169vDRgwwP71xYsXrcLCwmLbfP/995a7u7v1yiuv2Ne6d+9uNWvW7IqP7ePjY8XExJR5lkvOnDljSbLmzJljWZZlnT9/3nJxcbF69epl+fv727cbOnSoVbt2bauoqMg+pyRr4cKFlmVZ1s8//2xJst54443LPldOTo5Vs2ZNa/DgwcXW09PTLR8fnxLrpcnIyLCqVKlizZ8/37521113lfh7WLBggSXJmjp1aonHuPQa1q1bZ0myhg4detltfv86/5ckKz4+3v51fHy8Jcnq169fiW0vXLhQYm3JkiWWJGvjxo32taioKMvFxcXasWPHZWf6xz/+YUmyDh48aL8vPz/f8vX1LfbzBdxoOHIDOFl2drYkycvLq9yP4e7uLheX3/5zLiws1E8//aQaNWro9ttvL/Z2Us2aNXXy5Ent2LHjso9Vs2ZNbdu2rdgRn7Lw8/NT48aNtXHjRknSl19+KVdXV40YMUIZGRn67rvvJP125KZDhw6y2WylPk61atXk5uamDRs26Oeffy51m7Vr1+r8+fPq16+fMjMz7TdXV1eFh4dr/fr1fzhvUlKSXFxc1LNnT/tav3799OmnnxZ73g8++EC+vr4aMmRIice49Bo++OAD2Ww2xcfHX3ab8nj66adLrFWrVs3+54sXLyozM1N33nmnJNn/rouKirRixQp169ZNYWFhl52pd+/e8vDwKHb0Zs2aNcrMzNT/+3//r9xzA85G3ABO5u3tLem3c13Kq6ioSNOmTVOjRo3k7u4uX19f+fn5ae/evcrKyrJv9+KLL6pGjRpq166dGjVqpJiYGH355ZfFHmvy5Mnav3+/goKC1K5dO40bN07Hjh2z3//LL78oPT3dfjt79qz9vo4dO9rfdtq0aZPCwsIUFham2rVra9OmTcrOztaePXvUsWPHy74Wd3d3TZo0SZ9++qn8/f3VqVMnTZ48Wenp6fZtLoXSPffcIz8/v2K3zz77TGfOnPnD79n777+vdu3a6aefftKRI0d05MgRtW7dWvn5+Vq6dKl9u6NHj+r2229XlSqXv/7i6NGjCgwMVO3atf/weR3RoEGDEmvnzp3TsGHD5O/vr2rVqsnPz8++3aW/67Nnzyo7O1vNmze/4uPXrFlT3bp1K3bOVWJiourVq6d77rmnAl8JcH0RN4CTeXt7KzAwsNj5G46aMGGC4uLi1KlTJ73//vtas2aN1q5dq2bNmhX73S1NmjTRoUOHlJSUpA4dOuiDDz5Qhw4dih1x6N27t44dO6aZM2cqMDBQb7zxhpo1a6ZPP/1UkvTmm2+qbt269lvbtm3t+3bo0EGnTp3SsWPHtGnTJnXs2FE2m00dOnTQpk2btGXLFhUVFV0xbiRp+PDhOnz4sBISEuTh4aExY8aoSZMm+vrrryXJ/pree+89rV27tsTto48+uuLjf/fdd9qxY4c2b96sRo0a2W+XTtot7TyUq3W5IziFhYWX3ed/j9Jc0rt3b82fP19PP/20PvzwQ3322WdavXq1JJXr9/RERUXp2LFj2rJli3JycvTxxx+rX79+9iOBwI2IS8GBSuChhx7S22+/ra1bt6p9+/YO779s2TJ17txZ77zzTrH18+fPy9fXt9iap6en+vTpoz59+ig/P1+PPvqoXn/9dY0aNcp+SXbdunX17LPP6tlnn9WZM2fUpk0bvf7663rggQcUFRVljwCp+D/Al6Jl7dq12rFjh0aOHCnpt5OH586dq8DAQHl6eio0NPQPX1PDhg31/PPP6/nnn9d3332nVq1aacqUKXr//ffVsGFDSVKdOnXKdel2YmKiqlatqvfee0+urq7F7tu8ebNmzJihtLQ0/elPf1LDhg21bds2FRQUXPZ38TRs2FBr1qzRuXPnLnv0platWpJ++zv5Xz/88EOZ5/7555+VkpKi8ePHa+zYsfb1S0eyLvHz85O3t3eZgvn++++Xn5+fEhMTFR4ergsXLqh///5lngmojEhzoBL4+9//Lk9PTw0aNEgZGRkl7j969Kjeeuuty+7v6upa7EoZSVq6dKlOnTpVbO33lwu7ubmpadOmsixLBQUFKiwsLPY2lvRbQAQGBiovL0+SFBISosjISPstIiLCvm2DBg1Ur149TZs2TQUFBfb7OnbsqKNHj2rZsmW68847r/gWz4ULF0pcjt2wYUN5eXnZZ+jSpYu8vb01YcIEFRQUlHiM/32rrDSJiYnq2LGj+vTpo8cee6zYbcSIEZJkvwy6Z8+eyszM1KxZs0o8zqXvec+ePWVZlsaPH3/Zbby9veXr62s/J+mSOXPmXHHW/3UpxH7/dz19+vRiX7u4uKhHjx765JNP7JeilzaTJFWpUkX9+vXTv/71Ly1atEgtWrTQHXfcUeaZgMqIIzdAJdCwYUMtXrxYffr0UZMmTYr9huItW7Zo6dKlV/wsqYceekivvPKKoqOjddddd2nfvn1KTExUSEhIse3uu+8+BQQEKCIiQv7+/jp48KBmzZqlrl27ysvLS+fPn9ett96qxx57TC1btlSNGjX0+eefa8eOHZoyZUqZXkvHjh2VlJSkFi1a2I9WtGnTRp6enjp8+LAef/zxK+5/+PBh/eUvf1Hv3r3VtGlTValSRcuXL1dGRob69u0r6bdQmDt3rvr37682bdqob9++8vPzU1pamlauXKmIiIhSY0SStm3bpiNHjig2NrbU++vVq6c2bdooMTFRL774oqKiovR///d/iouL0/bt29WxY0fl5ubq888/17PPPqvu3burc+fO6t+/v2bMmKHvvvtO999/v4qKirRp0yZ17tzZ/lyDBg3SxIkTNWjQIIWFhWnjxo06fPhwmb6vl173pXOQCgoKVK9ePX322Wf6/vvvS2w7YcIEffbZZ7r77rv11FNPqUmTJvrxxx+1dOlSbd68WTVr1rRvGxUVpRkzZmj9+vWaNGlSmecBKi0nXqkF4HcOHz5sDR482AoODrbc3NwsLy8vKyIiwpo5c6Z18eJF+3alXQr+/PPPW3Xr1rWqVatmRUREWFu3brXuvvtu6+6777Zv949//MPq1KmTdcstt1ju7u5Ww4YNrREjRlhZWVmWZVlWXl6eNWLECKtly5aWl5eX5enpabVs2dJ+eXdZzJ4925JkPfPMM8XWIyMjLUlWSkpKsfXfXyKdmZlpxcTEWI0bN7Y8PT0tHx8fKzw83PrXv/5V4rnWr19vdenSxfLx8bE8PDyshg0bWk8++aS1c+fOy843ZMgQS5J19OjRy24zbtw4S5K1Z88ey7J+u/z65Zdftho0aGBVrVrVCggIsB577LFij/Gf//zHeuONN6zGjRtbbm5ulp+fn/XAAw9Yu3btsm9z4cIFa+DAgZaPj4/l5eVl9e7d234JfWmXgp89e7bEbCdPnrQeeeQRq2bNmpaPj4/Vq1cv6/Tp0yUew7Is64cffrCioqIsPz8/y93d3QoJCbFiYmKsvLy8Eo/brFkzy8XFxTp58uRlvy/AjcJmWb87vgkAuOm0bt1atWvXVkpKirNHAa4a59wAwE1u586d2r17t6Kiopw9ClAhOHIDADep/fv3a9euXZoyZYoyMzN17Ngxp32IKVCROHIDADepZcuWKTo6WgUFBVqyZAlhA2Nw5AYAABiFIzcAAMAoxA0AADDKTfdL/IqKinT69Gl5eXld1af1AgCA68eyLOXk5CgwMPAPP/vspoub06dPKygoyNljAACAcjhx4oRuvfXWK25z08WNl5eXpN++Od7e3k6eBgAAlEV2draCgoLs/45fyU0XN5feivL29iZuAAC4wZTllBJOKAYAAEYhbgAAgFGIGwAAYBTiBgAAGIW4AQAARiFuAACAUYgbAABgFOIGAAAYhbgBAABGIW4AAIBRiBsAAGAU4gYAABiFuAEAAEYhbgAAgFGIGwAAYJQqzh4AQMUKHrnS2SPAyY5P7OrsEQCn4sgNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAozg9bmbPnq3g4GB5eHgoPDxc27dvv+L206dP1+23365q1aopKChIzz33nC5evHidpgUAAJWdU+MmOTlZcXFxio+PV2pqqlq2bKkuXbrozJkzpW6/ePFijRw5UvHx8Tp48KDeeecdJScn66WXXrrOkwMAgMrKqXEzdepUDR48WNHR0WratKnmzZun6tWra8GCBaVuv2XLFkVEROjxxx9XcHCw7rvvPvXr1+8Pj/YAAICbh9PiJj8/X7t27VJkZOR/h3FxUWRkpLZu3VrqPnfddZd27dplj5ljx45p1apVevDBBy/7PHl5ecrOzi52AwAA5qrirCfOzMxUYWGh/P39i637+/vr22+/LXWfxx9/XJmZmerQoYMsy9J//vMfPf3001d8WyohIUHjx4+v0NkBAEDl5fQTih2xYcMGTZgwQXPmzFFqaqo+/PBDrVy5Uq+++upl9xk1apSysrLstxMnTlzHiQEAwPXmtCM3vr6+cnV1VUZGRrH1jIwMBQQElLrPmDFj1L9/fw0aNEiS1KJFC+Xm5uqpp57Syy+/LBeXkq3m7u4ud3f3in8BAACgUnLakRs3NzeFhoYqJSXFvlZUVKSUlBS1b9++1H0uXLhQImBcXV0lSZZlXbthAQDADcNpR24kKS4uTgMGDFBYWJjatWun6dOnKzc3V9HR0ZKkqKgo1atXTwkJCZKkbt26aerUqWrdurXCw8N15MgRjRkzRt26dbNHDgAAuLk5NW769Omjs2fPauzYsUpPT1erVq20evVq+0nGaWlpxY7UjB49WjabTaNHj9apU6fk5+enbt266fXXX3fWSwAAAJWMzbrJ3s/Jzs6Wj4+PsrKy5O3t7exxgAoXPHKls0eAkx2f2NXZIwAVzpF/v2+oq6UAAAD+CHEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoTo+b2bNnKzg4WB4eHgoPD9f27duvuP358+cVExOjunXryt3dXbfddptWrVp1naYFAACVXRVnPnlycrLi4uI0b948hYeHa/r06erSpYsOHTqkOnXqlNg+Pz9f9957r+rUqaNly5apXr16+uGHH1SzZs3rPzwAAKiUnBo3U6dO1eDBgxUdHS1JmjdvnlauXKkFCxZo5MiRJbZfsGCBzp07py1btqhq1aqSpODg4Os5MgAAqOSc9rZUfn6+du3apcjIyP8O4+KiyMhIbd26tdR9Pv74Y7Vv314xMTHy9/dX8+bNNWHCBBUWFl72efLy8pSdnV3sBgAAzOW0uMnMzFRhYaH8/f2Lrfv7+ys9Pb3UfY4dO6Zly5apsLBQq1at0pgxYzRlyhS99tprl32ehIQE+fj42G9BQUEV+joAAEDl4vQTih1RVFSkOnXq6O2331ZoaKj69Omjl19+WfPmzbvsPqNGjVJWVpb9duLEies4MQAAuN6cds6Nr6+vXF1dlZGRUWw9IyNDAQEBpe5Tt25dVa1aVa6urva1Jk2aKD09Xfn5+XJzcyuxj7u7u9zd3St2eAAAUGk57ciNm5ubQkNDlZKSYl8rKipSSkqK2rdvX+o+EREROnLkiIqKiuxrhw8fVt26dUsNGwAAcPNx6ttScXFxmj9/vt59910dPHhQzzzzjHJzc+1XT0VFRWnUqFH27Z955hmdO3dOw4YN0+HDh7Vy5UpNmDBBMTExznoJAACgknHqpeB9+vTR2bNnNXbsWKWnp6tVq1ZavXq1/STjtLQ0ubj8t7+CgoK0Zs0aPffcc7rjjjtUr149DRs2TC+++KKzXgIA4HeCR6509ghwsuMTuzr1+Z0aN5IUGxur2NjYUu/bsGFDibX27dvrq6++usZTAQCAG9UNdbUUAADAHyFuAACAUYgbAABgFOIGAAAYxeG4CQ4O1iuvvKK0tLRrMQ8AAMBVcThuhg8frg8//FAhISG69957lZSUpLy8vGsxGwAAgMPKFTe7d+/W9u3b1aRJEw0ZMkR169ZVbGysUlNTr8WMAAAAZVbuc27atGmjGTNm6PTp04qPj9c///lPtW3bVq1atdKCBQtkWVZFzgkAAFAm5f4lfgUFBVq+fLkWLlyotWvX6s4779TAgQN18uRJvfTSS/r888+1ePHiipwVAADgDzkcN6mpqVq4cKGWLFkiFxcXRUVFadq0aWrcuLF9m0ceeURt27at0EEBAADKwuG4adu2re69917NnTtXPXr0UNWqVUts06BBA/Xt27dCBgQAAHCEw3Fz7Ngx1a9f/4rbeHp6auHCheUeCgAAoLwcPqH4zJkz2rZtW4n1bdu2aefOnRUyFAAAQHk5HDcxMTE6ceJEifVTp04pJiamQoYCAAAoL4fj5sCBA2rTpk2J9datW+vAgQMVMhQAAEB5ORw37u7uysjIKLH+448/qkqVcl9ZDgAAUCEcjpv77rtPo0aNUlZWln3t/Pnzeumll3TvvfdW6HAAAACOcvhQy5tvvqlOnTqpfv36at26tSRp9+7d8vf313vvvVfhAwIAADjC4bipV6+e9u7dq8TERO3Zs0fVqlVTdHS0+vXrV+rvvAEAALieynWSjKenp5566qmKngUAAOCqlfsM4AMHDigtLU35+fnF1h9++OGrHgoAAKC8yvUbih955BHt27dPNpvN/unfNptNklRYWFixEwIAADjA4aulhg0bpgYNGujMmTOqXr26vvnmG23cuFFhYWHasGHDNRgRAACg7Bw+crN161atW7dOvr6+cnFxkYuLizp06KCEhAQNHTpUX3/99bWYEwAAoEwcPnJTWFgoLy8vSZKvr69Onz4tSapfv74OHTpUsdMBAAA4yOEjN82bN9eePXvUoEEDhYeHa/LkyXJzc9Pbb7+tkJCQazEjAABAmTkcN6NHj1Zubq4k6ZVXXtFDDz2kjh076pZbblFycnKFDwgAAOAIh+OmS5cu9j//+c9/1rfffqtz586pVq1a9iumAAAAnMWhc24KCgpUpUoV7d+/v9h67dq1CRsAAFApOBQ3VatW1Z/+9Cd+lw0AAKi0HL5a6uWXX9ZLL72kc+fOXYt5AAAArorD59zMmjVLR44cUWBgoOrXry9PT89i96emplbYcAAAAI5yOG569OhxDcYAAACoGA7HTXx8/LWYAwAAoEI4fM4NAABAZebwkRsXF5crXvbNlVQAAMCZHI6b5cuXF/u6oKBAX3/9td59912NHz++wgYDAAAoD4fjpnv37iXWHnvsMTVr1kzJyckaOHBghQwGAABQHhV2zs2dd96plJSUino4AACAcqmQuPn11181Y8YM1atXryIeDgAAoNwcflvq9x+QaVmWcnJyVL16db3//vsVOhwAAICjHI6badOmFYsbFxcX+fn5KTw8XLVq1arQ4QAAABzlcNw8+eST12AMAACAiuHwOTcLFy7U0qVLS6wvXbpU7777boUMBQAAUF4Ox01CQoJ8fX1LrNepU0cTJkyokKEAAADKy+G4SUtLU4MGDUqs169fX2lpaRUyFAAAQHk5fM5NnTp1tHfvXgUHBxdb37Nnj2655ZaKmuuGFTxypbNHgJMdn9jV2SMAwE3N4SM3/fr109ChQ7V+/XoVFhaqsLBQ69at07Bhw9S3b99rMSMAAECZOXzk5tVXX9Xx48f1l7/8RVWq/LZ7UVGRoqKiOOcGAAA4ncNx4+bmpuTkZL322mvavXu3qlWrphYtWqh+/frXYj4AAACHOBw3lzRq1EiNGjWqyFkAAACumsPn3PTs2VOTJk0qsT558mT16tWrQoYCAAAoL4fjZuPGjXrwwQdLrD/wwAPauHFjhQwFAABQXg7HzS+//CI3N7cS61WrVlV2dnaFDAUAAFBeDsdNixYtlJycXGI9KSlJTZs2rZChAAAAysvhE4rHjBmjRx99VEePHtU999wjSUpJSdHixYu1bNmyCh8QAADAEQ7HTbdu3bRixQpNmDBBy5YtU7Vq1dSyZUutW7dOtWvXvhYzAgAAlFm5LgXv2rWrunb97VfMZ2dna8mSJXrhhRe0a9cuFRYWVuiAAAAAjnD4nJtLNm7cqAEDBigwMFBTpkzRPffco6+++qoiZwMAAHCYQ0du0tPTtWjRIr3zzjvKzs5W7969lZeXpxUrVnAyMQAAqBTKfOSmW7duuv3227V3715Nnz5dp0+f1syZM6/lbAAAAA4r85GbTz/9VEOHDtUzzzzDxy4AAIBKq8xHbjZv3qycnByFhoYqPDxcs2bNUmZm5rWcDQAAwGFljps777xT8+fP148//qi//e1vSkpKUmBgoIqKirR27Vrl5ORcyzkBAADKxOGrpTw9PfXXv/5Vmzdv1r59+/T8889r4sSJqlOnjh5++OFyDTF79mwFBwfLw8ND4eHh2r59e5n2S0pKks1mU48ePcr1vAAAwDzlvhRckm6//XZNnjxZJ0+e1JIlS8r1GMnJyYqLi1N8fLxSU1PVsmVLdenSRWfOnLnifsePH9cLL7ygjh07lut5AQCAma4qbi5xdXVVjx499PHHHzu879SpUzV48GBFR0eradOmmjdvnqpXr64FCxZcdp/CwkI98cQTGj9+vEJCQq5mdAAAYJgKiZvyys/P165duxQZGWlfc3FxUWRkpLZu3XrZ/V555RXVqVNHAwcO/MPnyMvLU3Z2drEbAAAwl1PjJjMzU4WFhfL39y+27u/vr/T09FL32bx5s9555x3Nnz+/TM+RkJAgHx8f+y0oKOiq5wYAAJWXU+PGUTk5Oerfv7/mz58vX1/fMu0zatQoZWVl2W8nTpy4xlMCAABnKtcHZ1YUX19fubq6KiMjo9h6RkaGAgICSmx/9OhRHT9+XN26dbOvFRUVSZKqVKmiQ4cOqWHDhsX2cXd3l7u7+zWYHgAAVEZOPXLj5uam0NBQpaSk2NeKioqUkpKi9u3bl9i+cePG2rdvn3bv3m2/Pfzww+rcubN2797NW04AAMC5R24kKS4uTgMGDFBYWJjatWun6dOnKzc3V9HR0ZKkqKgo1atXTwkJCfLw8FDz5s2L7V+zZk1JKrEOAABuTk6Pmz59+ujs2bMaO3as0tPT1apVK61evdp+knFaWppcXG6oU4MAAIATOT1uJCk2NlaxsbGl3rdhw4Yr7rto0aKKHwgAANywOCQCAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAolSJuZs+ereDgYHl4eCg8PFzbt2+/7Lbz589Xx44dVatWLdWqVUuRkZFX3B4AANxcnB43ycnJiouLU3x8vFJTU9WyZUt16dJFZ86cKXX7DRs2qF+/flq/fr22bt2qoKAg3XfffTp16tR1nhwAAFRGTo+bqVOnavDgwYqOjlbTpk01b948Va9eXQsWLCh1+8TERD377LNq1aqVGjdurH/+858qKipSSkrKdZ4cAABURk6Nm/z8fO3atUuRkZH2NRcXF0VGRmrr1q1leowLFy6ooKBAtWvXvlZjAgCAG0gVZz55ZmamCgsL5e/vX2zd399f3377bZke48UXX1RgYGCxQPpfeXl5ysvLs3+dnZ1d/oEBAECl5/S3pa7GxIkTlZSUpOXLl8vDw6PUbRISEuTj42O/BQUFXecpAQDA9eTUuPH19ZWrq6syMjKKrWdkZCggIOCK+7755puaOHGiPvvsM91xxx2X3W7UqFHKysqy306cOFEhswMAgMrJqXHj5uam0NDQYicDXzo5uH379pfdb/LkyXr11Ve1evVqhYWFXfE53N3d5e3tXewGAADM5dRzbiQpLi5OAwYMUFhYmNq1a6fp06crNzdX0dHRkqSoqCjVq1dPCQkJkqRJkyZp7NixWrx4sYKDg5Weni5JqlGjhmrUqOG01wEAACoHp8dNnz59dPbsWY0dO1bp6elq1aqVVq9ebT/JOC0tTS4u/z3ANHfuXOXn5+uxxx4r9jjx8fEaN27c9RwdAABUQk6PG0mKjY1VbGxsqfdt2LCh2NfHjx+/9gMBAIAb1g19tRQAAMDvETcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAoxA3AADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxSKeJm9uzZCg4OloeHh8LDw7V9+/Yrbr906VI1btxYHh4eatGihVatWnWdJgUAAJWd0+MmOTlZcXFxio+PV2pqqlq2bKkuXbrozJkzpW6/ZcsW9evXTwMHDtTXX3+tHj16qEePHtq/f/91nhwAAFRGTo+bqVOnavDgwYqOjlbTpk01b948Va9eXQsWLCh1+7feekv333+/RowYoSZNmujVV19VmzZtNGvWrOs8OQAAqIycGjf5+fnatWuXIiMj7WsuLi6KjIzU1q1bS91n69atxbaXpC5dulx2ewAAcHOp4swnz8zMVGFhofz9/Yut+/v769tvvy11n/T09FK3T09PL3X7vLw85eXl2b/OysqSJGVnZ1/N6JdVlHfhmjwubhzX6merrPgZBD+DcLZr8TN46TEty/rDbZ0aN9dDQkKCxo8fX2I9KCjICdPgZuAz3dkT4GbHzyCc7Vr+DObk5MjHx+eK2zg1bnx9feXq6qqMjIxi6xkZGQoICCh1n4CAAIe2HzVqlOLi4uxfFxUV6dy5c7rllltks9mu8hXgf2VnZysoKEgnTpyQt7e3s8fBTYifQTgbP4PXjmVZysnJUWBg4B9u69S4cXNzU2hoqFJSUtSjRw9Jv8VHSkqKYmNjS92nffv2SklJ0fDhw+1ra9euVfv27Uvd3t3dXe7u7sXWatasWRHj4zK8vb35jxpOxc8gnI2fwWvjj47YXOL0t6Xi4uI0YMAAhYWFqV27dpo+fbpyc3MVHR0tSYqKilK9evWUkJAgSRo2bJjuvvtuTZkyRV27dlVSUpJ27typt99+25kvAwAAVBJOj5s+ffro7NmzGjt2rNLT09WqVSutXr3aftJwWlqaXFz+e1HXXXfdpcWLF2v06NF66aWX1KhRI61YsULNmzd31ksAAACViM0qy2nHQBnk5eUpISFBo0aNKvFWIHA98DMIZ+NnsHIgbgAAgFGc/huKAQAAKhJxAwAAjELcAAAAoxA3AADAKMQNKszs2bMVHBwsDw8PhYeHa/v27c4eCTeJjRs3qlu3bgoMDJTNZtOKFSucPRJuMgkJCWrbtq28vLxUp04d9ejRQ4cOHXL2WDct4gYVIjk5WXFxcYqPj1dqaqpatmypLl266MyZM84eDTeB3NxctWzZUrNnz3b2KLhJffHFF4qJidFXX32ltWvXqqCgQPfdd59yc3OdPdpNiUvBUSHCw8PVtm1bzZo1S9JvH6MRFBSkIUOGaOTIkU6eDjcTm82m5cuX2z/SBXCGs2fPqk6dOvriiy/UqVMnZ49z0+HIDa5afn6+du3apcjISPuai4uLIiMjtXXrVidOBgDOkZWVJUmqXbu2kye5ORE3uGqZmZkqLCy0f2TGJf7+/kpPT3fSVADgHEVFRRo+fLgiIiL4aCAncfpnSwEAYJKYmBjt379fmzdvdvYoNy3iBlfN19dXrq6uysjIKLaekZGhgIAAJ00FANdfbGys/v3vf2vjxo269dZbnT3OTYu3pXDV3NzcFBoaqpSUFPtaUVGRUlJS1L59eydOBgDXh2VZio2N1fLly7Vu3To1aNDA2SPd1DhygwoRFxenAQMGKCwsTO3atdP06dOVm5ur6OhoZ4+Gm8Avv/yiI0eO2L/+/vvvtXv3btWuXVt/+tOfnDgZbhYxMTFavHixPvroI3l5ednPN/Tx8VG1atWcPN3Nh0vBUWFmzZqlN954Q+np6WrVqpVmzJih8PBwZ4+Fm8CGDRvUuXPnEusDBgzQokWLrv9AuOnYbLZS1xcuXKgnn3zy+g4D4gYAAJiFc24AAIBRiBsAAGAU4gYAABiFuAEAAEYhbgAAgFGIGwAAYBTiBgAAGIW4AXDDsdlsWrFihbPHAFBJETcAKp309HQNGTJEISEhcnd3V1BQkLp161bs88sA4HL4bCkAlcrx48cVERGhmjVr6o033lCLFi1UUFCgNWvWKCYmRt9++62zRwRQyXHkBkCl8uyzz8pms2n79u3q2bOnbrvtNjVr1kxxcXH66quvSt3nxRdf1G233abq1asrJCREY8aMUUFBgf3+PXv2qHPnzvLy8pK3t7dCQ0O1c+dOSdIPP/ygbt26qVatWvL09FSzZs20atWq6/JaAVwbHLkBUGmcO3dOq1ev1uuvvy5PT88S99esWbPU/by8vLRo0SIFBgZq3759Gjx4sLy8vPT3v/9dkvTEE0+odevWmjt3rlxdXbV7925VrVpV0m+f5pyfn6+NGzfK09NTBw4cUI0aNa7ZawRw7RE3ACqNI0eOyLIsNW7c2KH9Ro8ebf9zcHCwXnjhBSUlJdnjJi0tTSNGjLA/bqNGjezbp6WlqWfPnmrRooUkKSQk5GpfBgAn420pAJWGZVnl2i85OVkREREKCAhQjRo1NHr0aKWlpdnvj4uL06BBgxQZGamJEyfq6NGj9vuGDh2q1157TREREYqPj9fevXuv+nUAcC7iBkCl0ahRI9lsNodOGt66daueeOIJPfjgg/r3v/+tr7/+Wi+//LLy8/Pt24wbN07ffPONunbtqnXr1qlp06Zavny5JGnQoEE6duyY+vfvr3379iksLEwzZ86s8NcG4PqxWeX9XyUAuAYeeOAB7du3T4cOHSpx3s358+dVs2ZN2Ww2LV++XD169NCUKVM0Z86cYkdjBg0apGXLlun8+fOlPke/fv2Um5urjz/+uMR9o0aN0sqVKzmCA9zAOHIDoFKZPXu2CgsL1a5dO33wwQf67rvvdPDgQc2YMUPt27cvsX2jRo2UlpampKQkHT16VDNmzLAflZGkX3/9VbGxsdqwYYN++OEHffnll9qxY4eaNGkiSRo+fLjWrFmj77//XqmpqVq/fr39PgA3Jk4oBlCphISEKDU1Va+//rqef/55/fjjj/Lz81NoaKjmzp1bYvuHH35Yzz33nGJjY5WXl6euXbtqzJgxGjdunCTJ1dVVP/30k6KiopSRkSFfX189+uijGj9+vCSpsLBQMTExOnnypLy9vXX//fdr2rRp1/MlA6hgvC0FAACMwttSAADAKMQNAAAwCnEDAACMQtwAAACjEDcAAMAoxA0AADAKcQMAAIxC3AAAAKMQNwAAwCjEDQAAMApxAwAAjELcAAAAo/x/jnT1G2fFK0EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def perform_bagging_and_voting(X_train, y_train, X_test, num_samples=5):\n",
    "\n",
    "    datasets = []\n",
    "    for i in range(num_samples):\n",
    "        indices = np.random.choice(len(X_train), 100, replace=True)\n",
    "        X_sample, y_sample = X_train[indices], y_train[indices]\n",
    "        datasets.append((X_sample, y_sample))\n",
    "    trees = []\n",
    "    for X_sample, y_sample in datasets:\n",
    "        tree = DecisionTreeClassifier(min_samples_split=3, max_depth=2)\n",
    "        tree.fit(X_sample, y_sample)\n",
    "        trees.append(tree)\n",
    "\n",
    "    predictions = []\n",
    "    for tree in trees:\n",
    "        prediction = tree.predict(X_test)\n",
    "        predictions.append(prediction)\n",
    "    majority_votes = np.array(predictions)\n",
    "    majority_votes = np.swapaxes(majority_votes, 0, 1)\n",
    "    final_predictions = []\n",
    "    for votes in majority_votes:\n",
    "        vote_count = Counter(votes)\n",
    "        final_predictions.append(vote_count.most_common(1)[0][0])\n",
    "    \n",
    "    return final_predictions\n",
    "\n",
    "# Perform bagging and voting\n",
    "final_predictions = perform_bagging_and_voting(X_reduced[:i], y_train[:i], X_reduced1)\n",
    "\n",
    "# Calculate total accuracy\n",
    "total_accuracy = np.mean(final_predictions == y_test)\n",
    "\n",
    "# Calculate class-wise accuracies\n",
    "class_accuracy = {}\n",
    "for class_label in np.unique(y_test):\n",
    "    correct = np.sum((final_predictions == y_test) & (y_test == class_label))\n",
    "    total = np.sum(y_test == class_label)\n",
    "    class_accuracy[class_label] = correct / total\n",
    "\n",
    "# Report the results\n",
    "print(\"Total Accuracy:\", total_accuracy)\n",
    "for class_label, accuracy in class_accuracy.items():\n",
    "    print(f\"Class {class_label} Accuracy:\", accuracy)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots()\n",
    "ax.bar(range(len(class_accuracy)), list(class_accuracy.values()), align='center')\n",
    "ax.set_xticks(range(len(class_accuracy)))\n",
    "ax.set_xticklabels(list(class_accuracy.keys()))\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_xlabel('Class')\n",
    "ax.set_title('Class-wise Accuracy')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
