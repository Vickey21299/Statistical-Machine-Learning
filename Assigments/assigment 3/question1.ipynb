{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "array = np.load('x_train.npy')\n",
    "\n",
    "print(array[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18623, 784)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Load the training data\n",
    "x_train = np.load('x_train.npy').reshape(-1, 28*28)\n",
    "\n",
    "labels = np.load('y_train.npy')  # Assuming you have labels for the data\n",
    "# Concatenate the data of the three classes\n",
    "finalLabels = []\n",
    "class_indices = {str(i): [] for i in range(3)}  # Assuming you have only 3 classes\n",
    "for i, label in enumerate(labels):\n",
    "    if (label < 3):  # Considering only the first 3 classes\n",
    "        class_indices[str(label)].append(i)\n",
    "\n",
    "data_class_0 = x_train[class_indices['0']]\n",
    "data_class_1 = x_train[class_indices['1']]\n",
    "data_class_2 = x_train[class_indices['2']]\n",
    "\n",
    "label_class_0 = labels[class_indices['0']]\n",
    "label_class_1 = labels[class_indices['1']]\n",
    "label_class_2 = labels[class_indices['2']]\n",
    "\n",
    "labels = np.concatenate((label_class_0, label_class_1, label_class_2), axis=0)\n",
    "\n",
    "\n",
    "# Concatenate data from all three classes\n",
    "X = np.concatenate((data_class_0, data_class_1, data_class_2), axis=0)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18623, 10)\n"
     ]
    }
   ],
   "source": [
    "def pca(data, n_components=10):\n",
    "    # Step 1: Calculate mean of the data\n",
    "    data_mean = np.mean(data, axis=0)\n",
    "    \n",
    "    # Step 2: Center the data\n",
    "    data_centered = data - data_mean\n",
    "    \n",
    "    # Step 3: Compute covariance matrix\n",
    "    covariance_matrix = np.cov(data_centered, rowvar=False)\n",
    "    \n",
    "    # Step 4: Compute eigenvectors and eigenvalues\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(covariance_matrix)\n",
    "    \n",
    "    # Step 5: Sort eigenvectors and eigenvalues in descending order\n",
    "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
    "    sorted_eigenvalues = eigenvalues[sorted_indices]\n",
    "    sorted_eigenvectors = eigenvectors[:, sorted_indices]\n",
    "    \n",
    "    # Step 6: Choose top n_components eigenvectors\n",
    "    U = sorted_eigenvectors[:, :n_components]\n",
    "    \n",
    "    # Step 7: Project the data onto the top n_components eigenvectors\n",
    "    Y = np.dot(U.T, data_centered.T)\n",
    "    \n",
    "    # Step 8: Reconstruct the data\n",
    "    x_reconstructed = np.dot(U, Y) + data_mean.reshape(-1, 1)\n",
    "    \n",
    "    # Step 9: Further reduce dimensionality if needed\n",
    "    Up = U[:, :n_components]\n",
    "    data_reduced = np.dot(Up.T, x_reconstructed)\n",
    "    \n",
    "    return Up.T , x_reconstructed\n",
    "pca_matrix1, x_reconstructed = pca(X, n_components=10)\n",
    "pca_matrix = np.dot(pca_matrix1, x_reconstructed).T\n",
    "print(pca_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "x_test = np.load('x_test.npy').reshape(-1, 28*28)\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "# Filter out samples from classes other than 0, 1, and 2\n",
    "class_indices_test = {str(i): [] for i in range(3)}\n",
    "for i, label in enumerate(y_test):\n",
    "    if label < 3:  # Considering only the first 3 classes\n",
    "        class_indices_test[str(label)].append(i)\n",
    "\n",
    "# Extract data corresponding to classes 0, 1, and 2\n",
    "data_class_0_test = x_test[class_indices_test['0']]\n",
    "data_class_1_test = x_test[class_indices_test['1']]\n",
    "data_class_2_test = x_test[class_indices_test['2']]\n",
    "\n",
    "# Concatenate data from all three classes vertically\n",
    "X_test = np.concatenate((data_class_0_test, data_class_1_test, data_class_2_test), axis=0)\n",
    "y_test_filtered = y_test[np.concatenate((class_indices_test['0'], class_indices_test['1'], class_indices_test['2']))]\n",
    "\n",
    "# Calculate accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'feature': 0, 'threshold': 33.76691272246312, 'left': {'class': 1}, 'right': {'class': 0}}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_gini(labels):\n",
    "    classes = np.unique(labels)\n",
    "    gini = 0\n",
    "    total_samples = len(labels)\n",
    "    for c in classes:\n",
    "        proportion = np.sum(labels == c) / total_samples\n",
    "        gini += proportion * (1 - proportion)\n",
    "    return gini\n",
    "\n",
    "def find_best_split(X, y):\n",
    "    best_gini = float('inf')\n",
    "    best_feature = None\n",
    "    best_threshold = None\n",
    "    \n",
    "    for feature in range(X.shape[1]):  # Loop over each feature\n",
    "        thresholds = np.unique(X[:, feature])  # Unique values in the feature\n",
    "        for threshold in thresholds:\n",
    "            left_mask = X[:, feature] <= threshold\n",
    "            right_mask = X[:, feature] > threshold\n",
    "            \n",
    "            left_gini = calculate_gini(y[left_mask])\n",
    "            right_gini = calculate_gini(y[right_mask])\n",
    "            \n",
    "            total_gini = (len(y[left_mask]) * left_gini + len(y[right_mask]) * right_gini) / len(y)\n",
    "            \n",
    "            if total_gini < best_gini:\n",
    "                best_gini = total_gini\n",
    "                best_feature = feature\n",
    "                best_threshold = threshold\n",
    "                \n",
    "    return best_feature, best_threshold\n",
    "\n",
    "def grow_decision_tree(X, y, max_nodes=2):\n",
    "    if max_nodes == 1 or len(np.unique(y)) == 1:\n",
    "        # If reached maximum nodes or all labels are the same, return leaf node\n",
    "        return {'class': np.argmax(np.bincount(y))}\n",
    "    \n",
    "    # Find the best split\n",
    "    best_feature, best_threshold = find_best_split(X, y)\n",
    "    \n",
    "    if best_feature is None:\n",
    "        # If no split improves purity, return leaf node\n",
    "        return {'class': np.argmax(np.bincount(y))}\n",
    "    \n",
    "    # Split the data\n",
    "    left_mask = X[:, best_feature] <= 90\n",
    "    right_mask = X[:, best_feature] > 40\n",
    "    \n",
    "    # Recursively grow the left and right subtrees\n",
    "    left_subtree = grow_decision_tree(X[left_mask], y[left_mask], max_nodes=max_nodes-1)\n",
    "    right_subtree = grow_decision_tree(X[right_mask], y[right_mask], max_nodes=max_nodes-1)\n",
    "    \n",
    "    return {'feature': best_feature, 'threshold': best_threshold, 'left': left_subtree, 'right': right_subtree}\n",
    "\n",
    "# Grow decision tree\n",
    "decision_tree = grow_decision_tree(pca_matrix, labels, max_nodes=2)\n",
    "print(decision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "x_test = np.load('x_test.npy').reshape(-1, 28*28)\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "# Filter out samples from classes other than 0, 1, and 2\n",
    "class_indices_test = {str(i): [] for i in range(3)}\n",
    "for i, label in enumerate(y_test):\n",
    "    if label < 3:  # Considering only the first 3 classes\n",
    "        class_indices_test[str(label)].append(i)\n",
    "\n",
    "# Extract data corresponding to classes 0, 1, and 2\n",
    "data_class_0_test = x_test[class_indices_test['0']]\n",
    "data_class_1_test = x_test[class_indices_test['1']]\n",
    "data_class_2_test = x_test[class_indices_test['2']]\n",
    "\n",
    "# Concatenate data from all three classes vertically\n",
    "X_test = np.concatenate((data_class_0_test, data_class_1_test, data_class_2_test), axis=0)\n",
    "y_test_filtered = y_test[np.concatenate((class_indices_test['0'], class_indices_test['1'], class_indices_test['2']))]\n",
    "\n",
    "#calculate the pca_matrix for the test data\n",
    "pca_matrix2, x_reconstructed2 = pca(X_test, n_components=10)\n",
    "pca_matrix_test = np.dot(pca_matrix2, x_reconstructed2).T\n",
    "# Calculate accuracy\n",
    "print(pca_matrix_test.shape)\n",
    "# Calculate accuracy for each class\n",
    "class_accuracies = {}\n",
    "for c in range(3):\n",
    "    class_mask = (y_test_filtered == c)\n",
    "    class_accuracy = calculate_accuracy(decision_tree, X_test[class_mask], y_test_filtered[class_mask])\n",
    "    class_accuracies[c] = class_accuracy\n",
    "\n",
    "print(\"Class-wise accuracies:\", class_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3147, 784)\n",
      "(3147,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test_filtered.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from collections import Counter\n",
    "\n",
    "# Define function to perform majority voting\n",
    "def majority_voting(predictions):\n",
    "    # Perform majority voting\n",
    "    voted_predictions = []\n",
    "    for i in range(len(predictions[0])):\n",
    "        votes = Counter([prediction[i] for prediction in predictions])\n",
    "        majority_vote = votes.most_common(1)[0][0]\n",
    "        voted_predictions.append(majority_vote)\n",
    "    return voted_predictions\n",
    "\n",
    "# Perform bagging with decision trees\n",
    "num_trees = 5\n",
    "tree_predictions = []\n",
    "\n",
    "for _ in range(num_trees):\n",
    "    # Generate a bootstrapped dataset\n",
    "    bootstrapped_X, bootstrapped_y = resample(x_train, labels, replace=True)\n",
    "    \n",
    "    # Grow decision tree on bootstrapped dataset\n",
    "    decision_tree = grow_decision_tree(bootstrapped_X, bootstrapped_y, max_nodes=3)\n",
    "    \n",
    "    # Predict class labels for test samples using decision tree\n",
    "    predictions = []\n",
    "    for sample in X_test:\n",
    "        prediction = predict_labels(decision_tree, sample)\n",
    "        predictions.append(prediction)\n",
    "    \n",
    "    # Append predictions to list\n",
    "    tree_predictions.append(predictions)\n",
    "\n",
    "# Perform majority voting\n",
    "voted_predictions = majority_voting(tree_predictions)\n",
    "\n",
    "# Calculate total accuracy\n",
    "total_correct = sum(1 for i in range(len(y_test_filtered)) if voted_predictions[i] == y_test_filtered[i])\n",
    "total_accuracy = total_correct / len(y_test_filtered)\n",
    "print(\"Total accuracy:\", total_accuracy)\n",
    "\n",
    "# Calculate class-wise accuracy\n",
    "class_correct = {c: 0 for c in range(3)}\n",
    "class_total = {c: 0 for c in range(3)}\n",
    "for i in range(len(y_test_filtered)):\n",
    "    if voted_predictions[i] == y_test_filtered[i]:\n",
    "        class_correct[y_test_filtered[i]] += 1\n",
    "    class_total[y_test_filtered[i]] += 1\n",
    "\n",
    "class_accuracy = {c: class_correct[c] / class_total[c] for c in range(3)}\n",
    "print(\"Class-wise accuracies:\", class_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
